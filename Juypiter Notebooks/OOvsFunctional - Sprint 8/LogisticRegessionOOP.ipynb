{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "    \n",
    "    def __init__(self,df,alpha=0.1,lambda_value=0): \n",
    "        self.n_iterations=1000\n",
    "        # assign the input arguments to class attributes\n",
    "        # INSERT CODE HERE\n",
    "        \n",
    "        self.X = df[df.columns.difference(['target'])]\n",
    "        self.y = df.target\n",
    "        self.n_features = len(list(self.X))\n",
    "        self.alpha = (alpha)\n",
    "        self.w = self._initialise_w(self.n_features)\n",
    "        self.lambda_value = lambda_value\n",
    "        # \"private\" methods are preceded with an underscore in the name\n",
    "        # in other programming languages such functions are treated differently\n",
    "        # in Python we use this convention as an indication to the user that they are\n",
    "        # intended to be called by other methods in the class and not from outside of the class\n",
    "    def set_alpha(self,alpha=0.1) :\n",
    "        self.alpha = alpha\n",
    "    def _safe_log(self, x):\n",
    "        return np.where(x==0, np.log(x+1e-10), np.log(x))\n",
    "\n",
    "    def _sigmoid(self, x):\n",
    "        \"\"\"Implements the sigmoid function\n",
    "                           1\n",
    "        sigmoid(x) =  -------------\n",
    "                      1 + exp(-x)\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : float or iterable\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        float or iterable\n",
    "        \"\"\"\n",
    "        return 1./(1 + np.exp(-x))\n",
    "        \n",
    "    def _calc_dJ_dw(self, X, y, w):\n",
    "        '''Function to calculate dJ/dw\n",
    "\n",
    "        Parameters:\n",
    "        X : 2d-array, feature matrix\n",
    "        y : 1d-array, true y values\n",
    "        w : 1d-array, linear regression model weights\n",
    "\n",
    "        Returns:\n",
    "        dJ_dw : 1d-array\n",
    "        '''\n",
    "        m = len(y)\n",
    "        ypred = self.predict(X)\n",
    "        dJ_dw = np.dot(X.T, (ypred - y)) / y.shape[0]\n",
    "        # Check that dJ_dw has the right shape\n",
    "        assert dJ_dw.shape == w.shape\n",
    "        return dJ_dw\n",
    "    \n",
    "    def _initialise_w(self, n_features):\n",
    "        '''Initialise the weights vector w with random values.\n",
    "\n",
    "        Parameters:\n",
    "        n_features : int, number of features \n",
    "\n",
    "        Returns:\n",
    "        w : 1d-array\n",
    "        '''\n",
    "        # Set a seed so we get predictable values\n",
    "        np.random.seed(1)\n",
    "        # create a random numpy array of features of length n_features\n",
    "        self.w = np.random.rand(n_features,)\n",
    "        # Check that w has the right shape\n",
    "        assert self.w.shape == (n_features,)\n",
    "        return self.w\n",
    "    \n",
    "    def _update_w(self, w, alpha, dJ_dw):\n",
    "        '''Update the weights vector w.\n",
    "\n",
    "        Parameters:\n",
    "        w : 1d-array, weights vector\n",
    "        alpha : float, learning rate\n",
    "        dJ_dw : 1d-array, gradients vector\n",
    "\n",
    "        Returns:\n",
    "        new_w : 1d-array, updated weights vector\n",
    "        '''    \n",
    "        new_w = w - (alpha * dJ_dw )\n",
    "        # Check the dimensions of new_w\n",
    "        assert new_w.shape == w.shape\n",
    "        return new_w\n",
    "    \n",
    "    def cost_function(self, y, ypred):\n",
    "        '''The cost function J(w) as defined in Equation (4).\n",
    "\n",
    "        Parameters:\n",
    "        ypred : 1d-array, y values predicted by model \n",
    "        y : 1d-array, true y values\n",
    "\n",
    "        Returns:\n",
    "        float, J (the cost)\n",
    "        '''\n",
    "        # m is the number of samples\n",
    "        m = y.shape[0]\n",
    "\n",
    "        # J is the cost\n",
    "        J = (-1 / m )  * ( sum(y * self._safe_log(ypred) + (1 - y) * self._safe_log(1 - ypred))  + (self.lambda_value * (np.sum(self.w**2))) )\n",
    "\n",
    "        # Check that J is a scalar\n",
    "        #assert J.shape == ()\n",
    "\n",
    "        return J\n",
    "    def predict_proba(self, y_pred):\n",
    "        # INSERT CODE HERE\n",
    "        return list(map(lambda x: 1 if x > 0.5 else 0, y_pred))\n",
    "    def predict(self, X):\n",
    "        '''The logistic regression model as defined in Equation (1).\n",
    "        It takes X and w as inputs and returns a 1d-array of predictions.\n",
    "\n",
    "        Parameters:\n",
    "        X : 2d-array, shape=(n_samples,n_features)\n",
    "        w : 1d-array, shape=(n_features,)\n",
    "\n",
    "        Returns:\n",
    "        ypred : 1d-array, shape=(n_samples,)\n",
    "        '''\n",
    "        # Check that the number of features in X is equal to the number features in the weights vector\n",
    "        assert X.shape[1] == len(self.w)\n",
    "        ypred = self._sigmoid(np.dot(X,self.w))\n",
    "        # Check that the number of predictions made is equal to the number of samples in X\n",
    "        assert len(ypred) == X.shape[0]\n",
    "        return ypred\n",
    "\n",
    "    def fit(self, verbose=False ):#, X, y, n_iterations=100, alpha=0.01, verbose=False):\n",
    "        # INSERT CODE HERE\n",
    "        '''Fit linear regression model to data X, y.\n",
    "\n",
    "        Parameters:\n",
    "        X : 2d-array, feature matrix shape=(m, n_features)\n",
    "        y : 1d-array, targets\n",
    "        n_iterations : int, number of iterations of gradient descent\n",
    "        alpha : float, learning rate\n",
    "        verbose : bool, prints the cost every 10 iterations\n",
    "\n",
    "        Returns:\n",
    "        w : nd-array, final weights matrix shape=(n_features,)\n",
    "        cost_values : 1d-array, cost at each iteration shape=(n_iterations,)\n",
    "        w_values : nd-array, weights at each iteration shape=(n_iterations, n_features)\n",
    "        '''\n",
    "\n",
    "        # We are going to save the values of the cost and w at each iteration for later analysis\n",
    "        cost_values = [] \n",
    "        w_values = [] \n",
    "\n",
    "        # Repeat n_iterations times\n",
    "        for i in range(self.n_iterations):\n",
    "\n",
    "            # Step 2: Calculate the gradient \n",
    "            dJ_dw = self._calc_dJ_dw(self.X, self.y, self.w)\n",
    "\n",
    "            # Step 3: Update w\n",
    "            self.w = self._update_w(self.w, self.alpha, dJ_dw)# INSERT CODE HERE\n",
    "\n",
    "            # Calculate the cost \n",
    "            cost = self.cost_function( self.y , self.predict(self.X) )# INSERT CODE HERE\n",
    "\n",
    "            if verbose and i % 100 == 0:\n",
    "                print('Iteration {}: Cost={:.6f}'.format(i, cost))\n",
    "\n",
    "            # Save the values of the cost and w after each iteration\n",
    "            cost_values.append(cost)\n",
    "            w_values.append(self.w)\n",
    "\n",
    "        cost_values = np.array(cost_values)\n",
    "        w_values = np.array(w_values)\n",
    "\n",
    "        return self.w, cost_values, w_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_classification\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "%matplotlib inline\n",
    "\n",
    "# Edit the commands below as required\n",
    "def get_data():\n",
    "    '''Load classification data for the exercise.\n",
    "    \n",
    "    Returns:\n",
    "    data : pandas DataFrame\n",
    "    '''\n",
    "    X, y = make_classification(n_samples=1000, n_features=10, n_informative=8, n_redundant=2, n_classes=2, random_state=42, n_clusters_per_class=1)\n",
    "    \n",
    "    df = pd.DataFrame(X, columns=['feature_'+str(i) for i in range(10)])\n",
    "    df['target'] = y\n",
    "    return X , y , df\n",
    "X , y , df = get_data()\n",
    "# Initialse Model\n",
    "model1 = LogisticRegression(df,0.01,100)\n",
    "\n",
    "\n",
    "print(model1.lambda_value)\n",
    "\n",
    "# Fit Model\n",
    "fit = model1.fit()\n",
    "#print(model1.w)\n",
    "# Make Predictions\n",
    "\n",
    "y_pred = model1.predict_proba(model1.predict(X))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.94      0.96       498\n",
      "          1       0.94      0.98      0.96       502\n",
      "\n",
      "avg / total       0.96      0.96      0.96      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import make_classification\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'df'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-67a051c0a983>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_classification\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m.5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'df'"
     ]
    }
   ],
   "source": [
    "X, y = make_classification(200, 2, 2, 0, weights=[.5, .5], random_state=15)\n",
    "clf = LogisticRegression().fit(X[:100], y[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx, yy = np.mgrid[-5:5:.01, -5:5:.01]\n",
    "grid = np.c_[xx.ravel(), yy.ravel()]\n",
    "probs = clf.predict_proba(grid)[:, 1].reshape(xx.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 3 is out of bounds for axis 1 with size 2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-49c10e8addc3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0max_c\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_ticks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m.25\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m.75\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m ax.scatter(X[:,0], X[:, 3], c=y[:], s=50,\n\u001b[0m\u001b[0;32m      9\u001b[0m            \u001b[0mcmap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"RdBu\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvmin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m.2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvmax\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1.2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m            edgecolor=\"white\", linewidth=1)\n",
      "\u001b[1;31mIndexError\u001b[0m: index 3 is out of bounds for axis 1 with size 2"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, ax = plt.subplots(figsize=(8, 6))\n",
    "contour = ax.contourf(xx, yy, probs, 25, cmap=\"RdBu\",\n",
    "                      vmin=0, vmax=1)\n",
    "ax_c = f.colorbar(contour)\n",
    "ax_c.set_label(\"$P(y = 1)$\")\n",
    "ax_c.set_ticks([0, .25, .5, .75, 1])\n",
    "\n",
    "ax.scatter(X[:,0], X[:, 3], c=y[:], s=50,\n",
    "           cmap=\"RdBu\", vmin=-.2, vmax=1.2,\n",
    "           edgecolor=\"white\", linewidth=1)\n",
    "\n",
    "ax.set(aspect=\"equal\",\n",
    "       xlim=(-5, 5), ylim=(-5, 5),\n",
    "       xlabel=\"$X_1$\", ylabel=\"$X_2$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
