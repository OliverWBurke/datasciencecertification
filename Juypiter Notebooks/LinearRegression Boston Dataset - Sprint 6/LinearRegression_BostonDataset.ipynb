{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminary Questions:\n",
    "\n",
    "### What is the purpose of splitting your data into training, validation and test sets?\n",
    "\n",
    "Training data will allow us to build up the model\n",
    "Validation set will allow us to take the model and tune it, for example setting parameters on regularsation lamda\n",
    "Test data set will allows us to check that the model performs well on a dataset that it has not seen before. The training set should follow the same general distribution of the training set\n",
    "\n",
    "### What is the cost function for linear regression? \n",
    "\n",
    "J(theta) = 1/2m SUM( (predicted-Y - Y )^2  )\n",
    "where predicted-y = Theta0 + Theta1X1 + Theta2X2 ...\n",
    "\n",
    "### How would you modify the cost function for linear regression to use regularisation?\n",
    "\n",
    "J(theta) = 1/2m SUM( (predicted-Y - Y )^2  + 1/mLamda(SUM (from j=1>m (Thetaj^2)))\n",
    "Where lamda = Regularisation Parameter\n",
    "Could use ABS(Thetaj) rather than (ThetaJ)^2 \n",
    "\n",
    "\n",
    "### How does the size of the regularisation parameter impact your model?\n",
    "\n",
    "Larger regularisation parameter will mean that the theta parameter weights will be smaller\n",
    "\n",
    "### What metric should you use to evaluate the accuracy of a linear regression model?\n",
    "\n",
    "Value of the Minimised cost function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Import And Initial Investigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "boston = load_boston()\n",
    "\n",
    "#print(boston)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "boston.DESCR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- CRIM     per capita crime rate by town\n",
    "- ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
    "- INDUS    proportion of non-retail business acres per town\n",
    "- CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
    "- NOX      nitric oxides concentration (parts per 10 million)\n",
    "- RM       average number of rooms per dwelling\n",
    "- AGE      proportion of owner-occupied units built prior to 1940\n",
    "- DIS      weighted distances to five Boston employment centres\n",
    "- RAD      index of accessibility to radial highways\n",
    "- TAX      full-value property-tax rate per 10,000usd\n",
    "- PTRATIO  pupil-teacher ratio by town\n",
    "- B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
    "- LSTAT    % lower status of the population\n",
    "- MEDV     Median value of owner-occupied homes in 1000usd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = boston.target\n",
    "X = boston.data\n",
    "X.shape\n",
    "#print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data   = pd.DataFrame(boston.data, columns = boston.feature_names)\n",
    "target = pd.DataFrame(boston.target, columns = [\"TARGET\"])\n",
    "\n",
    "data['TARGET'] = target\n",
    "\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(data.isnull(), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in boston.feature_names:\n",
    "    plt.hist(data[i],bins = 100)\n",
    "    plt.title(i)\n",
    "    plt.show()\n",
    "    plt.boxplot(data[i])\n",
    "    plt.title(i)\n",
    "    plt.show()\n",
    "    plt.scatter(data[i], data['TARGET'])\n",
    "    plt.title(i)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in boston.feature_names:\n",
    "    for j in boston.feature_names:\n",
    "        if i == j :\n",
    "            print(\"same\")\n",
    "        else:\n",
    "            plt.scatter(data[i], data[j])\n",
    "            plt.title(i+\" vs \"+j)\n",
    "            plt.xlabel(i)\n",
    "            plt.ylabel(j)\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(target[\"TARGET\"],bins = 100)\n",
    "plt.show()\n",
    "plt.boxplot(target[\"TARGET\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Initial Predicition with raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    " \n",
    "# Split into training and testing datasets\n",
    "# The random_state=0 kwarg ensures that the split is performed in a consistent manner between runs\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "model = LinearRegression()\n",
    " \n",
    "# Fit training set\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = model.predict(X_test)\n",
    " \n",
    " \n",
    "# Prediction metric\n",
    "naive_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "print(naive_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot\n",
    "plt.scatter(y_test, y_pred)\n",
    "plt.xlabel('true price')\n",
    "plt.ylabel('predicted price')\n",
    "plt.title('Boston house price prediction with linear regression model')\n",
    "plt.show()\n",
    " \n",
    "# Distribution of errors\n",
    "plt.hist(y_pred - y_test,bins = range(-20,11,1))\n",
    "plt.xlabel('difference in true and predicted price')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attempts\n",
    "\n",
    "- Remove outliers in target, values of 50\n",
    "  - RMSE Improvement - 1.4568695846892066\n",
    "-Add Standard Scaler\n",
    "  - RMSE Improvement - 1.456869584689211 - Barely any improvement\n",
    "-Replace Standard with MinMax Scaler\n",
    "  - RMSE Improvement - 1.4568695846892137 - Barely any improvement, but best scaling\n",
    "-Replace Standard with MaxAbs Scaler\n",
    "  - RMSE Improvement - 1.456869584689212 - Worse than MinMax\n",
    "-Add categorisation on CHAS feature\n",
    "  - RMSE Improvement - 1.4568695847061575 - Improvement\n",
    "  \n",
    "- Loop through to remove features one by one\n",
    "Removing CHAS and INDUS have a positive impact - Remove these two together leads to 4.304458421612283, improvement of 1.4792003656685777\n",
    "Removing all other features has a negative impact individially\n",
    "Removed Feature\tNew RMSE\tImpact\n",
    "CHAS\t4.313259982\t0.01352922015\n",
    "INDUS\t4.318445876\t0.008343326533\n",
    "AGE\t    4.326751297\t3.79E-05\n",
    "ZN\t    4.33557273\t-0.008783527861\n",
    "NOX\t    4.3659072\t-0.03911799755\n",
    "B\t    4.393902229\t-0.06711302657\n",
    "CRIM\t4.405942413\t-0.07915321079\n",
    "RAD\t    4.42633282\t-0.09954361702\n",
    "TAX\t    4.447770195\t-0.1209809927\n",
    "DIS\t    4.504328654\t-0.1775394516\n",
    "LSTAT\t4.590714818\t-0.2639256156\n",
    "PTRATIO\t4.705479732\t-0.3786905294\n",
    "RM\t    4.985348228\t-0.6585590251\n",
    "\n",
    "- Remove CHAS and INDUS and the repeat process\n",
    "Removed Feature\tNew RMSE\tImpact\n",
    "AGE\t    4.306313597\t-0.001855175676\n",
    "ZN\t    4.312388958\t-0.00793053648\n",
    "NOX\t    4.345536505\t-0.04107808292\n",
    "B\t    4.372303799\t-0.06784537708\n",
    "CRIM\t4.383219661\t-0.07876123917\n",
    "RAD\t    4.404340957\t-0.09988253532\n",
    "TAX\t    4.440388143\t-0.1359297214\n",
    "DIS\t    4.486801427\t-0.1823430053\n",
    "LSTAT\t4.56257363\t-0.2581152082\n",
    "PTRATIO\t4.709273147\t-0.4048147255\n",
    "RM\t    4.982456124\t-0.6779977027\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "def basic_train_and_run(X_train,X_test,y_train,y_test) :\n",
    "# Split into training and testing datasets\n",
    "# The random_state=0 kwarg ensures that the split is performed in a consistent manner between runs\n",
    "\n",
    "    model = LinearRegression()\n",
    " \n",
    "# Fit training set\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "    y_pred = model.predict(X_test)\n",
    " \n",
    " \n",
    "# Prediction metric\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    rmse_improvement = 4.304458421612283  - rmse\n",
    "    return(y_pred,rmse,rmse_improvement)\n",
    "    #return(rmse_improvement)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_performance (rmse,rmse_imporvement,y_test,y_pred, model_performance, show_graphs):\n",
    "    print(\"RMSE            : \"+str(rmse))\n",
    "    print(\"RMSE Improvement: \"+str(rmse_improvement))\n",
    "    if show_graphs == True :\n",
    "        # Scatter plot\n",
    "        plt.scatter(y_test, y_pred)\n",
    "        plt.xlabel('true price')\n",
    "        plt.ylabel('predicted price')\n",
    "        plt.title('Boston house price prediction with linear regression model')\n",
    "        plt.show()\n",
    "\n",
    "        # Distribution of errors\n",
    "        plt.hist(y_pred - y_test,bins = range(-20,11,1))\n",
    "        plt.xlabel('difference in true and predicted price')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y = boston.target\n",
    "X = boston.data\n",
    "data = pd.DataFrame(X, columns = boston.feature_names)\n",
    "\n",
    "data['TARGET'] = target\n",
    "#X_engineered_train = X_engineered_train.drop(columns =['CRIM'])\n",
    "#y_engineered_train = y_engineered_train.drop(columns =['CRIM'])\n",
    "#print(X_engineered_train)\n",
    "\n",
    "from sklearn import preprocessing\n",
    "import math\n",
    "\n",
    "\n",
    "# the 50 values look like outliers to me\n",
    "data.drop(data[data.TARGET == 50].index, inplace=True)\n",
    "\n",
    "y = data.TARGET\n",
    "X = data.drop([\"TARGET\",\"CHAS\",\"INDUS\"], axis = 1)\n",
    "\n",
    "\n",
    "lstat = X[\"LSTAT\"]\n",
    "sqrtLSTAT = []\n",
    "for i in lstat:\n",
    "    sqrtLSTAT.append(i ** -0.6)\n",
    "X[\"srtLSTAT\"] = sqrtLSTAT\n",
    "rad = X[\"RAD\"]\n",
    "binaryRad = []\n",
    "for i in rad:\n",
    "    if i > 10:\n",
    "        binaryRad.append(1)\n",
    "    else:\n",
    "        binaryRad.append(0)\n",
    "X[\"binaryRAD\"] = binaryRad\n",
    "\n",
    "\n",
    "tax = X[\"TAX\"]\n",
    "binaryTax = []\n",
    "for i in tax:\n",
    "    if i > 500:\n",
    "        binaryTax.append(1)\n",
    "    else:\n",
    "        binaryTax.append(0)\n",
    "X[\"binaryTAX\"] = binaryTax\n",
    "\n",
    "b = X[\"B\"]\n",
    "binaryB = []\n",
    "for i in b:\n",
    "    if i > 335:\n",
    "        binaryB.append(1)\n",
    "    else:\n",
    "        binaryB.append(0)\n",
    "X[\"binaryB\"] = binaryB\n",
    "\n",
    "zn = X[\"ZN\"]\n",
    "binaryZN = []\n",
    "for i in zn:\n",
    "    if i > 20:\n",
    "        binaryZN.append(1)\n",
    "    else:\n",
    "        binaryZN.append(0)\n",
    "X[\"binaryZN\"] = binaryZN\n",
    "#X = X.drop(\"ZN\",axis = 1)\n",
    "\n",
    "\n",
    "crime = X[\"CRIM\"]\n",
    "binaryCRIME = []\n",
    "for i in crime:\n",
    "    if i > 20:\n",
    "        binaryCRIME.append(1)\n",
    "    else:\n",
    "        binaryCRIME.append(0)\n",
    "X[\"binaryCRIME\"] = binaryCRIME\n",
    "X = X.drop(\"CRIM\",axis = 1)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, test_size=0.2)\n",
    "\n",
    "\n",
    "    \n",
    "scaler = preprocessing.MinMaxScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "   \n",
    "y_pred, rmse, rmse_improvement = basic_train_and_run(X_train, X_test, y_train, y_test)\n",
    "\n",
    "model_performance(rmse,rmse_improvement, y_test,y_pred,True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "def better_train_and_run(X_train,X_test,y_train,y_test,alpha) :\n",
    "# Split into training and testing datasets\n",
    "# The random_state=0 kwarg ensures that the split is performed in a consistent manner between runs\n",
    "    from sklearn.linear_model import Ridge\n",
    "    from sklearn.linear_model import Lasso\n",
    "    model = Ridge(alpha=alpha)\n",
    " \n",
    "# Fit training set\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "    y_pred = model.predict(X_test)\n",
    " \n",
    " \n",
    "# Prediction metric\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    rmse_improvement = 4.304458421612283  - rmse\n",
    "    return(y_pred,rmse,rmse_improvement)\n",
    "    #return(rmse_improvement)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphaVals = []\n",
    "#print(alphaVals)\n",
    "\n",
    "alphaVals = [0.001,0.003,0.01,0.03,0.1,0.3,1,3,10]\n",
    "for i in alphaVals:\n",
    "    alpha = i\n",
    "    print(alpha)\n",
    "    y_pred, rmse, rmse_improvement = better_train_and_run(X_train, X_test, y_train, y_test,alpha)\n",
    "\n",
    "    model_performance(rmse,rmse_improvement, y_test,y_pred,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
